{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy, pandas and mysqlalchemy (following what you have learned in previous lessons):\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Load and Evaluate the Datasets\n",
    "\n",
    "#### In this challenge we will load two SQL tables from [this link](https://relational.fit.cvut.cz/dataset/Stats). We will then proceed to evaluate the data to see what type of cleaning and manipulation is necessary.\n",
    "\n",
    "In the cell below, create a mysql engine using the link provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dfaa755aaf7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://relational.fit.cvut.cz/dataset/Stats\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mysql+pymysql://'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\matrix\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\matrix\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_or_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# create url.URL object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mplugins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instantiate_plugins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\matrix\\lib\\site-packages\\sqlalchemy\\engine\\url.py\u001b[0m in \u001b[0;36mmake_url\u001b[1;34m(name_or_url)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_parse_rfc1738_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mname_or_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\matrix\\lib\\site-packages\\sqlalchemy\\engine\\url.py\u001b[0m in \u001b[0;36m_parse_rfc1738_args\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mcomponents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"host\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mipv4host\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mipv6host\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         raise exc.ArgumentError(\n",
      "\u001b[1;32m~\\.conda\\envs\\matrix\\lib\\site-packages\\sqlalchemy\\engine\\url.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, drivername, username, password, host, port, database, query)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "engine = create_engine('mysql+pymysql://username:password@localhost/users')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this connection to load the `users` table. Load this table into a variable called `users`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start examining the dataset.\n",
    "\n",
    "First look at the first five rows using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, examine the column names and types to see if there is a type mismatch. Use the `dtypes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll examine the `describe` function to see the descriptive statistics for the numeric variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's load the posts table in the cell below.\n",
    "\n",
    "Use the same mysql engine to load the posts table into a dataframe called `posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's repeat what we did with the `users` table and print the first 5 rows, the data types of each column and describe the numeric data.\n",
    "\n",
    "Do this in the following 3 cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Prepare the Datasets for Merging and Merge\n",
    "\n",
    "#### We would like to join a subset of columns from each table. To ease the process, let's create a new dataframe containing a subset of columns for both `posts` and `users`\n",
    "\n",
    "In the cell below, create a new dataframe called `posts_subset` containing only the columns: `Id`, `Score`, `OwnerUserID`, `ViewCount` ,`CommentCount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a dataframe called `users_subset` containing only the columns `Id`, `Reputation`, `Views`, `UpVotes`, `DownVotes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will note that the Id column does not refer to the same thing in both tables. In the posts table, it refers to the post ID and in the users table it refers to the user ID. \n",
    "\n",
    "In the `users_subset` dataframe, rename the `Id` column to `UserId`. Do this using the option `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `posts_subset` dataframe, rename the `Id` column to `PostId`. Do this using the option `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the only column that the two tables have in common as the user ID. However, this column is called `UserId` in the `users_subset` table and `OwnerUserId` in the `posts_subset` table. Using what we have previously learned about merging two dataframes and looking at the documentation [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html), merge the two dataframes. Name the merged dataframe `stackoverflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if you have kept both key columns (if you join by making one of the columns an index first, this can be avoided).\n",
    "\n",
    "If both columns are present in `stackoverflow`, drop `OwnerUserId`. Do this using `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Cleaning Up the Data\n",
    "\n",
    "Now that we have merged the two dataframes, let's handle the missing values.\n",
    "\n",
    "Find the number of missing values in each column by applying the `isna()` function to the dataframe. Then apply the `sum()` function to that to find the count of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that about half of all observations in the view count column are missing. Let's examine these observations and why they have missing data. Create a subset of rows that have a missing value in the `ViewCount`. Look at the `describe()` function for that subset. You output should look like in the table below.\n",
    "\n",
    "![describe table](../describe-table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is a mix of users. They do not have a high comment count but they do have some upvotes and downvotes. Therefore, it would not make sense to fill these values with zero. \n",
    "\n",
    "If we investigate further, we will see that there are some users that have view counts missing for some posts but not others. We will cover different ways of investigating further in future lessons. What we can certainly say is that we should not fill all cells with the same values. One way to fill the values is using linear interpolation. Linear interpolation assumes that there is a line between two points and places all observations between the two points along that line. You can read more about linear interpolation [here](https://en.wikipedia.org/wiki/Linear_interpolation).\n",
    "\n",
    "To apply linear interpolation to our missing data, we use the `interpolate` function in pandas. You can read the documentation for this function [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html).\n",
    "\n",
    "Apply the `interpolate` function to the `ViewCount` column. Use `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Fill the Missing Data Using Linear Regression\n",
    "\n",
    "We have learned about linear regression in the prework. To read more about linear regression in Python, click [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "Create a linear model where the Y variable is the `ViewCount` and the X variable is `Score`. Make sure to use only rows that do not contain `NaN` by filtering them out.\n",
    "\n",
    "Use this regression model to produce a fitted value for every `NaN`. Using the `np.where` function, assign the predicted value only to rows where you have a `NaN`.\n",
    "\n",
    "Tip: If you get an error when creating your linear model, reshape the data to the correct shape (a 2D array) by appending `.values.reshape(-1, 1)` to the column. Also, transform the predicted data from a numpy array back to a dataframe and use only one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that both `UserId` and `PostsId` are treated as numeric even though they do not describe anything quantitative about the data. We would like to exclude them from any numeric calculations. To do this, we should change them from numeric to string. Transform each column from numeric to string using the `astype` function and pass the argument `'str'` to the function. Since we cannot do this in place, assign these new values back to their original column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would like to simplify the comment count variable by bucketing this variable. \n",
    "\n",
    "In the cell below, we have created 5 bins. Bucket this variable into equal width bins using the `cut` function. Create a new column called `CommentBins` and assign the bucketed data to this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
